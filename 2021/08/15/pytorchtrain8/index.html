

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar/tou.jpeg">
  <link rel="icon" href="/img/avatar/tou.jpeg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="zheng">
  <meta name="keywords" content="">
  
    <meta name="description" content="利用pytorch训练你的深度学习模型-8-具体网络分析">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-15-pytorch-8-具体网络分析">
<meta property="og:url" content="https://truth-zheng.github.io/2021/08/15/pytorchtrain8/index.html">
<meta property="og:site_name" content="Sage的生活学习笔记">
<meta property="og:description" content="利用pytorch训练你的深度学习模型-8-具体网络分析">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://truth-zheng.github.io/img/dlenv/0.jfif">
<meta property="article:published_time" content="2021-08-15T14:00:00.000Z">
<meta property="article:modified_time" content="2021-08-18T12:01:48.000Z">
<meta property="article:author" content="zheng">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://truth-zheng.github.io/img/dlenv/0.jfif">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>深度学习-15-pytorch-8-具体网络分析 - Sage的生活学习笔记</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"truth-zheng.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"gtag":null,"woyaola":null,"cnzz":null},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Sage的学习生活笔记</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg/2.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深度学习-15-pytorch-8-具体网络分析"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-08-15 22:00" pubdate>
          2021年8月15日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          4.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          42 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">深度学习-15-pytorch-8-具体网络分析</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    <!-- compatible with older versions-->
                    本文最后更新于：2021年8月18日 晚上
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <blockquote>
<p>创作声明：主要内容参考于张贤同学<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/265394674">https://zhuanlan.zhihu.com/p/265394674</a></p>
</blockquote>
<p>这篇文章主要介绍了 图像分类的 inference，其中会着重介绍 <code>ResNet</code>。</p>
<h2 id="模型概览"><a href="#模型概览" class="headerlink" title="模型概览"></a>模型概览</h2><p>在<code>torchvision.model</code>中，有很多封装好的模型。</p>
<p><img src="/img/pytorchtrain8/1.png" srcset="/img/loading.gif" lazyload><br> 可以分类 3 类：</p>
<ul>
<li>经典网络<ul>
<li>alexnet</li>
<li>vgg</li>
<li>resnet</li>
<li>inception</li>
<li>densenet</li>
<li>googlenet</li>
</ul>
</li>
<li>轻量化网络<ul>
<li>squeezenet</li>
<li>mobilenet</li>
<li>shufflenetv2</li>
</ul>
</li>
<li>自动神经结构搜索方法的网络<ul>
<li>mnasnet</li>
</ul>
</li>
</ul>
<h2 id="ResNet18-的使用"><a href="#ResNet18-的使用" class="headerlink" title="ResNet18 的使用"></a>ResNet18 的使用</h2><p>以 <code>ResNet 18</code> 为例。</p>
<p>首先加载训练好的模型参数：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">resnet18 = models.resnet18()<br><br># 修改全连接层的输出<br>num_ftrs = resnet18.fc.in_features<br>resnet18.fc = nn.Linear(num_ftrs, <span class="hljs-number">2</span>)<br><br># 加载模型参数<br><span class="hljs-keyword">checkpoint</span> = torch.<span class="hljs-keyword">load</span>(m_path)<br>resnet18.load_state_dict(<span class="hljs-keyword">checkpoint</span>[<span class="hljs-string">&#x27;model_state_dict&#x27;</span>])<br></code></pre></td></tr></table></figure>

<p>然后比较重要的是把模型放到 GPU 上，并且转换到<code>eval</code>模式：</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs autoit">resnet18.<span class="hljs-keyword">to</span>(device)<br>resnet18.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>

<p>在inference 时，主要流程如下：</p>
<ul>
<li><p>代码要放在<code>with torch.no_grad():</code>下。<code>torch.no_grad()</code>会关闭反向传播，可以减少内存、加快速度。</p>
</li>
<li><p>根据路径读取图片，把图片转换为 tensor，然后使用<code>unsqueeze_(0)</code>方法把形状扩大为$B \times C \times H \times W$，再把 tensor 放到 GPU 上 。</p>
</li>
<li><p>模型的输出数据<code>outputs</code>的形状是$1 \times 2$，表示 <code>batch_size</code> 为 1，分类数量为 2。<code>torch.max(outputs,0)</code>是返回<code>outputs</code>中<strong>每一列</strong>最大的元素和索引，<code>torch.max(outputs,1)</code>是返回<code>outputs</code>中<strong>每一行</strong>最大的元素和索引。</p>
<p>这里使用<code>_, pred_int = torch.max(outputs.data, 1)</code>返回最大元素的索引，然后根据索引获得 label：<code>pred_str = classes[int(pred_int)]</code>。</p>
</li>
</ul>
<p>关键代码如下：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> idx, img_name <span class="hljs-keyword">in</span> enumerate(img_names):<br><br>        path_img = os.path.<span class="hljs-keyword">join</span>(img_dir, img_name)<br><br>        # step <span class="hljs-number">1</span>/<span class="hljs-number">4</span> : <span class="hljs-type">path</span> <span class="hljs-comment">--&gt; img</span><br>        img_rgb = Image.<span class="hljs-keyword">open</span>(path_img).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br><br>        # step <span class="hljs-number">2</span>/<span class="hljs-number">4</span> : img <span class="hljs-comment">--&gt; tensor</span><br>        img_tensor = img_transform(img_rgb, inference_transform)<br>        img_tensor.unsqueeze_(<span class="hljs-number">0</span>)<br>        img_tensor = img_tensor.<span class="hljs-keyword">to</span>(device)<br><br>        # step <span class="hljs-number">3</span>/<span class="hljs-number">4</span> : tensor <span class="hljs-comment">--&gt; vector</span><br>        outputs = resnet18(img_tensor)<br><br>        # step <span class="hljs-number">4</span>/<span class="hljs-number">4</span> : <span class="hljs-keyword">get</span> label<br>        _, pred_int = torch.max(outputs.data, <span class="hljs-number">1</span>)<br>        pred_str = classes[<span class="hljs-type">int</span>(pred_int)]<br></code></pre></td></tr></table></figure>

<p>全部代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><span class="hljs-keyword">import</span> enviroments<br>BASE_DIR = os.path.dirname(os.path.abspath(__file__))<br><span class="hljs-comment"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br>device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># config</span><br>vis = <span class="hljs-literal">True</span><br><span class="hljs-comment"># vis = False</span><br>vis_row = <span class="hljs-number">4</span><br><br>norm_mean = [<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>]<br>norm_std = [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>]<br><br>inference_transform = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">256</span>),<br>    transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    transforms.ToTensor(),<br>    transforms.Normalize(norm_mean, norm_std),<br>])<br><br>classes = [<span class="hljs-string">&quot;ants&quot;</span>, <span class="hljs-string">&quot;bees&quot;</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">img_transform</span>(<span class="hljs-params">img_rgb, transform=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将数据转换为模型读取的形式</span><br><span class="hljs-string">    :param img_rgb: PIL Image</span><br><span class="hljs-string">    :param transform: torchvision.transform</span><br><span class="hljs-string">    :return: tensor</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">if</span> transform <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;找不到transform！必须有transform对img进行处理&quot;</span>)<br><br>    img_t = transform(img_rgb)<br>    <span class="hljs-keyword">return</span> img_t<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_img_name</span>(<span class="hljs-params">img_dir, <span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;jpg&quot;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    获取文件夹下format格式的文件名</span><br><span class="hljs-string">    :param img_dir: str</span><br><span class="hljs-string">    :param format: str</span><br><span class="hljs-string">    :return: list</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    file_names = os.listdir(img_dir)<br>    <span class="hljs-comment"># 使用 list(filter(lambda())) 筛选出 jpg 后缀的文件</span><br>    img_names = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x.endswith(<span class="hljs-built_in">format</span>), file_names))<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(img_names) &lt; <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;&#123;&#125;下找不到&#123;&#125;格式数据&quot;</span>.<span class="hljs-built_in">format</span>(img_dir, <span class="hljs-built_in">format</span>))<br>    <span class="hljs-keyword">return</span> img_names<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_model</span>(<span class="hljs-params">m_path, vis_model=<span class="hljs-literal">False</span></span>):<br><br>    resnet18 = models.resnet18()<br><br>    <span class="hljs-comment"># 修改全连接层的输出</span><br>    num_ftrs = resnet18.fc.in_features<br>    resnet18.fc = nn.Linear(num_ftrs, <span class="hljs-number">2</span>)<br><br>    <span class="hljs-comment"># 加载模型参数</span><br>    checkpoint = torch.load(m_path)<br>    resnet18.load_state_dict(checkpoint[<span class="hljs-string">&#x27;model_state_dict&#x27;</span>])<br><br><br>    <span class="hljs-keyword">if</span> vis_model:<br>        <span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br>        summary(resnet18, input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>), device=<span class="hljs-string">&quot;cpu&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> resnet18<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br><br>    img_dir = os.path.join(enviroments.hymenoptera_data_dir,<span class="hljs-string">&quot;val/bees&quot;</span>)<br>    model_path = <span class="hljs-string">&quot;./checkpoint_14_epoch.pkl&quot;</span><br>    time_total = <span class="hljs-number">0</span><br>    img_list, img_pred = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br><br>    <span class="hljs-comment"># 1. data</span><br>    img_names = get_img_name(img_dir)<br>    num_img = <span class="hljs-built_in">len</span>(img_names)<br><br>    <span class="hljs-comment"># 2. model</span><br>    resnet18 = get_model(model_path, <span class="hljs-literal">True</span>)<br>    resnet18.to(device)<br>    resnet18.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> idx, img_name <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(img_names):<br><br>            path_img = os.path.join(img_dir, img_name)<br><br>            <span class="hljs-comment"># step 1/4 : path --&gt; img</span><br>            img_rgb = Image.<span class="hljs-built_in">open</span>(path_img).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br><br>            <span class="hljs-comment"># step 2/4 : img --&gt; tensor</span><br>            img_tensor = img_transform(img_rgb, inference_transform)<br>            img_tensor.unsqueeze_(<span class="hljs-number">0</span>)<br>            img_tensor = img_tensor.to(device)<br><br>            <span class="hljs-comment"># step 3/4 : tensor --&gt; vector</span><br>            time_tic = time.time()<br>            outputs = resnet18(img_tensor)<br>            time_toc = time.time()<br><br>            <span class="hljs-comment"># step 4/4 : visualization</span><br>            _, pred_int = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>            pred_str = classes[<span class="hljs-built_in">int</span>(pred_int)]<br><br>            <span class="hljs-keyword">if</span> vis:<br>                img_list.append(img_rgb)<br>                img_pred.append(pred_str)<br><br>                <span class="hljs-keyword">if</span> (idx+<span class="hljs-number">1</span>) % (vis_row*vis_row) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> num_img == idx+<span class="hljs-number">1</span>:<br>                    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(img_list)):<br>                        plt.subplot(vis_row, vis_row, i+<span class="hljs-number">1</span>).imshow(img_list[i])<br>                        plt.title(<span class="hljs-string">&quot;predict:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(img_pred[i]))<br>                    plt.show()<br>                    plt.close()<br>                    img_list, img_pred = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br><br>            time_s = time_toc-time_tic<br>            time_total += time_s<br><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&#123;:d&#125;/&#123;:d&#125;: &#123;&#125; &#123;:.3f&#125;s &#x27;</span>.<span class="hljs-built_in">format</span>(idx + <span class="hljs-number">1</span>, num_img, img_name, time_s))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\ndevice:&#123;&#125; total time:&#123;:.1f&#125;s mean:&#123;:.3f&#125;s&quot;</span>.<br>          <span class="hljs-built_in">format</span>(device, time_total, time_total/num_img))<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;GPU name:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(torch.cuda.get_device_name()))<br></code></pre></td></tr></table></figure>

<p>总结一下 inference 阶段需要注意的事项：</p>
<ul>
<li>确保 model 处于 eval 状态，而非 trainning 状态</li>
<li>设置 torch.no_grad()，减少内存消耗，加快运算速度</li>
<li>数据预处理需要保持一致，比如 RGB 或者 rBGR</li>
</ul>
<h2 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h2><p>以 ResNet 为例：</p>
<p><img src="/img/pytorchtrain8/2.png" srcset="/img/loading.gif" lazyload><br> 一个残差块有2条路径$F(x)$和$x$，$F(x)$路径拟合残差，不妨称之为残差路径；$x$路径为<code>identity mapping</code>恒等映射，称之为<code>shortcut</code>。图中的⊕为<code>element-wise addition</code>，要求参与运算的$F(x)$和$x$的尺寸要相同。</p>
<p><code>shortcut</code> 路径大致可以分成2种，取决于残差路径是否改变了<code>feature map</code>数量和尺寸。</p>
<ul>
<li>一种是将输入<code>x</code>原封不动地输出。</li>
<li>另一种则需要经过$1×1$卷积来升维或者降采样，主要作用是将输出与$F(x)$路径的输出保持<code>shape</code>一致，对网络性能的提升并不明显。</li>
</ul>
<p>两种结构如下图所示：</p>
<p><img src="/img/pytorchtrain8/3.png" srcset="/img/loading.gif" lazyload><br> <code>ResNet</code> 中，使用了上面 2 种 <code>shortcut</code>。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>ResNet 有很多变种，包括 <code>ResNet 18</code>、<code>ResNet 34</code>、<code>ResNet 50</code>、<code>ResNet 101</code>、<code>ResNet 152</code>，网络结构对比如下：</p>
<p><img src="/img/pytorchtrain8/4.png" srcset="/img/loading.gif" lazyload><br> <code>ResNet</code> 的各个变种，数据处理大致流程如下：</p>
<ul>
<li>输入的图片形状是$3 \times 224 \times 224$。</li>
<li>图片经过 <code>conv1</code> 层，输出图片大小为 $ 64 \times 112 \times 112$。</li>
<li>图片经过 <code>max pool</code> 层，输出图片大小为 $ 64 \times 56 \times 56 $。</li>
<li>图片经过 <code>conv2</code> 层，输出图片大小为 $ 64 \times 56 \times 56$。<strong>（注意，图片经过这个 <code>layer</code>, 大小是不变的）</strong></li>
<li>图片经过 <code>conv3</code> 层，输出图片大小为 $ 128 \times 28 \times 28$。</li>
<li>图片经过 <code>conv4</code> 层，输出图片大小为 $ 256 \times 14 \times 14$。</li>
<li>图片经过 <code>conv5</code> 层，输出图片大小为 $ 512 \times 7 \times 7$。</li>
<li>图片经过 <code>avg pool</code> 层，输出大小为 $ 512 \times 1 \times 1$。</li>
<li>图片经过 <code>fc</code> 层，输出维度为 $ num_classes$，表示每个分类的 <code>logits</code>。</li>
</ul>
<p>下面，我们称每个 <code>conv</code> 层为一个 <code>layer</code>（第一个 <code>conv</code> 层就是一个卷积层，因此第一个 <code>conv</code> 层除外）。</p>
<p>其中 <code>ResNet 18</code>、<code>ResNet 34</code> 的每个 <code>layer</code> 由多个 <code>BasicBlock</code> 组成，只是每个 <code>layer</code> 里堆叠的 <code>BasicBlock</code> 数量不一样。</p>
<p>而 <code>ResNet 50</code>、<code>ResNet 101</code>、<code>ResNet 152</code> 的每个 <code>layer</code> 由多个 <code>Bottleneck</code> 组成，只是每个 <code>layer</code> 里堆叠的 <code>Bottleneck</code> 数量不一样。</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>我们来看看各个 <code>ResNet</code> 的源码，首先从构造函数开始。</p>
<h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><h4 id="ResNet-18"><a href="#ResNet-18" class="headerlink" title="ResNet 18"></a>ResNet 18</h4><p><code>resnet18</code> 的构造函数如下。</p>
<p><code>[2, 2, 2, 2]</code> 表示有 4 个 <code>layer</code>，每个 layer 中有 2 个 <code>BasicBlock</code>。</p>
<p><code>conv1</code>为 1 层，<code>conv2</code>、<code>conv3</code>、<code>conv4</code>、<code>conv5</code>均为 4 层（每个 <code>layer</code> 有 2 个 <code>BasicBlock</code>，每个 <code>BasicBlock</code> 有 2 个卷积层），总共为 16 层，最后一层全连接层，$总层数 &#x3D; 1+ 4 \times 4 + 1 &#x3D; 18$，依此类推。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet18</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, progress=<span class="hljs-literal">True</span>, **kwargs</span>):<br>    <span class="hljs-string">r&quot;&quot;&quot;ResNet-18 model from</span><br><span class="hljs-string">    `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span><br><span class="hljs-string">        progress (bool): If True, displays a progress bar of the download to stderr</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> _resnet(<span class="hljs-string">&#x27;resnet18&#x27;</span>, BasicBlock, [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>], pretrained, progress,<br>                   **kwargs)<br></code></pre></td></tr></table></figure>

<h4 id="ResNet-34"><a href="#ResNet-34" class="headerlink" title="ResNet 34"></a>ResNet 34</h4><p><code>resnet 34</code> 的构造函数如下。</p>
<p><code>[3, 4, 6, 3]</code> 表示有 4 个 <code>layer</code>，每个 <code>layer</code> 的 <code>BasicBlock</code> 数量分别为 3, 4, 6, 3。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet34</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, progress=<span class="hljs-literal">True</span>, **kwargs</span>):<br>    <span class="hljs-string">r&quot;&quot;&quot;ResNet-34 model from</span><br><span class="hljs-string">    `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span><br><span class="hljs-string">        progress (bool): If True, displays a progress bar of the download to stderr</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> _resnet(<span class="hljs-string">&#x27;resnet34&#x27;</span>, BasicBlock, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>], pretrained, progress,<br>                   **kwargs)<br></code></pre></td></tr></table></figure>

<h4 id="ResNet-50"><a href="#ResNet-50" class="headerlink" title="ResNet 50"></a>ResNet 50</h4><p><code>resnet 50</code> 的构造函数如下。</p>
<p><code>[3, 4, 6, 3]</code> 表示有 4 个 <code>layer</code>，每个 <code>layer</code> 的 <code>Bottleneck</code> 数量分别为 3, 4, 6, 3。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet50</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, progress=<span class="hljs-literal">True</span>, **kwargs</span>):<br>    <span class="hljs-string">r&quot;&quot;&quot;ResNet-50 model from</span><br><span class="hljs-string">    `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span><br><span class="hljs-string">        progress (bool): If True, displays a progress bar of the download to stderr</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> _resnet(<span class="hljs-string">&#x27;resnet50&#x27;</span>, Bottleneck, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>], pretrained, progress,<br>                   **kwargs)<br></code></pre></td></tr></table></figure>

<p>依此类推，<code>ResNet 101</code> 和 <code>ResNet 152</code> 也是由多个 <code>layer</code> 组成的。</p>
<h3 id="resnet"><a href="#resnet" class="headerlink" title="_resnet()"></a>_resnet()</h3><p>上面所有的构造函数中，都调用了 <code>_resnet()</code> 方法来创建网络，下面来看看 <code>_resnet()</code> 方法。</p>
<figure class="highlight stan"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stan">def _resnet(arch, <span class="hljs-built_in">block</span>, layers, pretrained, progress, **kwargs):<br>    <span class="hljs-title">model</span> = ResNet(<span class="hljs-built_in">block</span>, layers, **kwargs)<br>    <span class="hljs-comment"># 加载预训练好的模型参数</span><br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = load_state_dict_from_url(model_urls[arch],<br>                                              progress=progress)<br>        <span class="hljs-title">model</span>.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> <span class="hljs-title">model</span><br></code></pre></td></tr></table></figure>

<p>可以看到，在 <code>_resnet()</code> 方法中，又调用了 <code>ResNet()</code> 方法创建模型，然后加载训练好的模型参数。</p>
<h3 id="ResNet-的构造函数"><a href="#ResNet-的构造函数" class="headerlink" title="ResNet()的构造函数"></a>ResNet()的构造函数</h3><p>构造函数的重要参数如下：</p>
<ul>
<li>block：每个 <code>layer</code> 里面使用的 <code>block</code>，可以是 <code>BasicBlock</code> <code>Bottleneck</code>。</li>
<li>num_classes：分类数量，用于构建最后的全连接层。</li>
<li>layers：一个 list，表示每个 <code>layer</code> 中 <code>block</code> 的数量。</li>
</ul>
<p>构造函数的主要流程如下：</p>
<ul>
<li><p>判断是否传入 <code>norm_layer</code>，没有传入，则使用 <code>BatchNorm2d</code>。</p>
</li>
<li><p>判断是否传入空洞卷积参数 <code>replace_stride_with_dilation</code>，如果不指定，则赋值为 <code>[False, False, False]</code>，表示不使用空洞卷积。</p>
</li>
<li><p>读取分组卷积的参数 <code>groups</code>，<code>width_per_group</code>。</p>
</li>
<li><p>然后真正开始构造网络。</p>
</li>
<li><p><code>conv1</code> 层的结构是 <code>Conv2d -&gt; norm_layer -&gt; ReLU</code>。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">self.conv1 = nn.Conv2d(3, self.inplanes, <span class="hljs-attribute">kernel_size</span>=7, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=3, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>self.bn1 = norm_layer(self.inplanes)<br>self.relu = nn.ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>conv2</code> 层的代码如下，对应于 <code>layer1</code>，这个 <code>layer</code> 的参数没有指定 <code>stride</code>，默认 <code>stride=1</code>，因此这个 <code>layer</code> 不会改变图片大小：</p>
<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs oxygene"><span class="hljs-keyword">self</span>.layer1 = <span class="hljs-keyword">self</span>._make_layer(<span class="hljs-keyword">block</span>, <span class="hljs-number">64</span>, layers[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>conv3</code> 层的代码如下，对应于 <code>layer2</code>（注意这个 <code>layer</code> 指定 <code>stride=2</code>，会降采样，详情看下面 <code>_make_layer</code> 的讲解）：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">self</span>.layer2 = self._make_layer(block, <span class="hljs-number">128</span>, layers[<span class="hljs-number">1</span>], stride=<span class="hljs-number">2</span>, dilate=replace_stride_with_dilation[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>conv4</code> 层的代码如下，对应于 <code>layer3</code>（注意这个 <code>layer</code> 指定 <code>stride=2</code>，会降采样，详情看下面 <code>_make_layer</code> 的讲解）：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">self</span>.layer3 = self._make_layer(block, <span class="hljs-number">256</span>, layers[<span class="hljs-number">2</span>], stride=<span class="hljs-number">2</span>,<br><span class="hljs-attribute">dilate</span>=replace_stride_with_dilation[<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>conv5</code> 层的代码如下，对应于 <code>layer4</code>（注意这个 <code>layer</code> 指定 <code>stride=2</code>，会降采样，详情看下面 <code>_make_layer</code> 的讲解）：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">self</span>.layer4 = self._make_layer(block, <span class="hljs-number">512</span>, layers[<span class="hljs-number">3</span>], stride=<span class="hljs-number">2</span>,<br><span class="hljs-attribute">dilate</span>=replace_stride_with_dilation[<span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure>
</li>
<li><p>接着是 <code>AdaptiveAvgPool2d</code> 层和 <code>fc</code> 层。</p>
</li>
<li><p>最后是网络参数的初始：</p>
<ul>
<li>卷积层采用 <code>kaiming_normal_()</code> 初始化方法。</li>
<li><code>bn</code> 层和 <code>GroupNorm</code> 层初始化为 <code>weight=1</code>，<code>bias=0</code>。</li>
<li>其中每个 <code>BasicBlock</code> 和 <code>Bottleneck</code> 的最后一层 <code>bn</code> 的 <code>weight=0</code>，可以提升准确率 0.2~0.3%。</li>
</ul>
</li>
</ul>
<p>完整的构造函数代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, block, layers, num_classes=<span class="hljs-number">1000</span>, zero_init_residual=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">             groups=<span class="hljs-number">1</span>, width_per_group=<span class="hljs-number">64</span>, replace_stride_with_dilation=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">             norm_layer=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-built_in">super</span>(ResNet, <span class="hljs-variable language_">self</span>).__init__()<br>    <span class="hljs-comment"># 使用 bn 层</span><br>    <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        norm_layer = nn.BatchNorm2d<br>    <span class="hljs-variable language_">self</span>._norm_layer = norm_layer<br><br>    <span class="hljs-variable language_">self</span>.inplanes = <span class="hljs-number">64</span><br>    <span class="hljs-variable language_">self</span>.dilation = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> replace_stride_with_dilation <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># each element in the tuple indicates if we should replace</span><br>        <span class="hljs-comment"># the 2x2 stride with a dilated convolution instead</span><br>        replace_stride_with_dilation = [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(replace_stride_with_dilation) != <span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;replace_stride_with_dilation should be None &quot;</span><br>                         <span class="hljs-string">&quot;or a 3-element tuple, got &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(replace_stride_with_dilation))<br>    <span class="hljs-variable language_">self</span>.groups = groups<br>    <span class="hljs-variable language_">self</span>.base_width = width_per_group<br>    <span class="hljs-comment"># 对应于 conv1</span><br>    <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-variable language_">self</span>.inplanes, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>,<br>                           bias=<span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.bn1 = norm_layer(<span class="hljs-variable language_">self</span>.inplanes)<br>    <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># 对应于 conv2</span><br>    <span class="hljs-variable language_">self</span>.maxpool = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-variable language_">self</span>.layer1 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">64</span>, layers[<span class="hljs-number">0</span>])<br>    <span class="hljs-comment"># 对应于 conv3</span><br>    <span class="hljs-variable language_">self</span>.layer2 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">128</span>, layers[<span class="hljs-number">1</span>], stride=<span class="hljs-number">2</span>,<br>                                   dilate=replace_stride_with_dilation[<span class="hljs-number">0</span>])<br>    对应于 conv4<br>    <span class="hljs-variable language_">self</span>.layer3 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">256</span>, layers[<span class="hljs-number">2</span>], stride=<span class="hljs-number">2</span>,<br>                                   dilate=replace_stride_with_dilation[<span class="hljs-number">1</span>])<br>    对应于 conv5<br>    <span class="hljs-variable language_">self</span>.layer4 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">512</span>, layers[<span class="hljs-number">3</span>], stride=<span class="hljs-number">2</span>,<br>                                   dilate=replace_stride_with_dilation[<span class="hljs-number">2</span>])<br>    <span class="hljs-variable language_">self</span>.avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    <span class="hljs-variable language_">self</span>.fc = nn.Linear(<span class="hljs-number">512</span> * block.expansion, num_classes)<br><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>            nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm)):<br>            nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>            nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Zero-initialize the last BN in each residual branch,</span><br>    <span class="hljs-comment"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span><br>    <span class="hljs-comment"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span><br>    <span class="hljs-keyword">if</span> zero_init_residual:<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, Bottleneck):<br>                nn.init.constant_(m.bn3.weight, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, BasicBlock):<br>                nn.init.constant_(m.bn2.weight, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>

<h3 id="forward"><a href="#forward" class="headerlink" title="forward()"></a>forward()</h3><p>在 <code>ResNet</code> 中，网络经过层层封装，因此<code>forward()</code> 方法非常简洁。</p>
<p>数据变换大致流程如下：</p>
<ul>
<li>输入的图片形状是$3 \times 224 \times 224$。</li>
<li>图片经过 <code>conv1</code> 层，输出图片大小为 $ 64 \times 112 \times 112$。</li>
<li>图片经过 <code>max pool</code> 层，输出图片大小为 $ 64 \times 56 \times 56 $。</li>
<li>对于 <code>ResNet 18</code>、<code>ResNet 34</code> （使用 <code>BasicBlock</code>）：<ul>
<li>图片经过 <code>conv2</code> 层，对应于 <code>layer1</code>，输出图片大小为 $ 64 \times 56 \times 56$。<strong>（注意，图片经过这个 <code>layer</code>, 大小是不变的）</strong></li>
<li>图片经过 <code>conv3</code> 层，对应于 <code>layer2</code>，输出图片大小为 $ 128 \times 28 \times 28$。</li>
<li>图片经过 <code>conv4</code> 层，对应于 <code>layer3</code>，输出图片大小为 $ 256 \times 14 \times 14$。</li>
<li>图片经过 <code>conv5</code> 层，对应于 <code>layer4</code>，输出图片大小为 $ 512 \times 7 \times 7$。</li>
<li>图片经过 <code>avg pool</code> 层，输出大小为 $ 512 \times 1 \times 1$。</li>
</ul>
</li>
<li>对于 <code>ResNet 50</code>、<code>ResNet 101</code>、<code>ResNet 152</code>（使用 <code>Bottleneck</code>）：<ul>
<li>图片经过 <code>conv2</code> 层，对应于 <code>layer1</code>，输出图片大小为 $ 256 \times 56 \times 56$。<strong>（注意，图片经过这个 <code>layer</code>, 大小是不变的）</strong></li>
<li>图片经过 <code>conv3</code> 层，对应于 <code>layer2</code>，输出图片大小为 $ 512 \times 28 \times 28$。</li>
<li>图片经过 <code>conv4</code> 层，对应于 <code>layer3</code>，输出图片大小为 $ 1024 \times 14 \times 14$。</li>
<li>图片经过 <code>conv5</code> 层，对应于 <code>layer4</code>，输出图片大小为 $ 2048 \times 7 \times 7$。</li>
<li>图片经过 <code>avg pool</code> 层，输出大小为 $ 2048 \times 1 \times 1$。</li>
</ul>
</li>
<li>图片经过 <code>fc</code> 层，输出维度为 $ num_classes$，表示每个分类的 <code>logits</code>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward_impl</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># See note [TorchScript super()]</span><br><br>    <span class="hljs-comment"># conv1</span><br>    <span class="hljs-comment"># x: [3, 224, 224] -&gt; [64, 112, 112]</span><br>    x = <span class="hljs-variable language_">self</span>.conv1(x)<br>    x = <span class="hljs-variable language_">self</span>.bn1(x)<br>    x = <span class="hljs-variable language_">self</span>.relu(x)<br><br>    <span class="hljs-comment"># conv2</span><br>    <span class="hljs-comment"># x: [64, 112, 112] -&gt; [64, 56, 56]</span><br>    x = <span class="hljs-variable language_">self</span>.maxpool(x)<br><br>    <span class="hljs-comment"># x: [64, 56, 56] -&gt; [64, 56, 56]</span><br>    <span class="hljs-comment"># x 经过第一个 layer, 大小是不变的</span><br>    x = <span class="hljs-variable language_">self</span>.layer1(x)<br><br>    <span class="hljs-comment"># conv3</span><br>    <span class="hljs-comment"># x: [64, 56, 56] -&gt; [128, 28, 28]</span><br>    x = <span class="hljs-variable language_">self</span>.layer2(x)<br><br>    <span class="hljs-comment"># conv4</span><br>    <span class="hljs-comment"># x: [128, 28, 28] -&gt; [256, 14, 14]</span><br>    x = <span class="hljs-variable language_">self</span>.layer3(x)<br><br>    <span class="hljs-comment"># conv5</span><br>    <span class="hljs-comment"># x: [256, 14, 14] -&gt; [512, 7, 7]</span><br>    x = <span class="hljs-variable language_">self</span>.layer4(x)<br><br>    <span class="hljs-comment"># x: [512, 7, 7] -&gt; [512, 1, 1]</span><br>    x = <span class="hljs-variable language_">self</span>.avgpool(x)<br>    x = torch.flatten(x, <span class="hljs-number">1</span>)<br>    x = <span class="hljs-variable language_">self</span>.fc(x)<br><br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>

<p>在构造函数中可以看到，上面每个 <code>layer</code> 都是使用 <code>_make_layer()</code> 方法来创建层的，下面来看下 <code>_make_layer()</code> 方法。</p>
<h3 id="make-layer"><a href="#make-layer" class="headerlink" title="_make_layer()"></a>_make_layer()</h3><p><code>_make_layer()</code>方法的参数如下：</p>
<ul>
<li>block：每个 <code>layer</code> 里面使用的 <code>block</code>，可以是 <code>BasicBlock</code>，<code>Bottleneck</code>。</li>
<li>planes：输出的通道数</li>
<li>blocks：一个整数，表示该层 <code>layer</code> 有多少个 <code>block</code>。</li>
<li>stride：第一个 <code>block</code> 的卷积层的 <code>stride</code>，默认为 1。注意，只有在每个 <code>layer</code> 的第一个 <code>block</code> 的第一个卷积层使用该参数。</li>
<li>dilate：是否使用空洞卷积。</li>
</ul>
<p>主要流程如下：</p>
<ul>
<li>判断空洞卷积，计算 <code>previous_dilation</code> 参数。</li>
<li>判断 <code>stride</code> 是否为 1，输入通道和输出通道是否相等。如果这两个条件都不成立，那么表明需要建立一个 1 X 1 的卷积层，来<strong>改变通道数和改变图片大小</strong>。具体是建立 <code>downsample</code> 层，包括 <code>conv1x1 -&gt; norm_layer</code>。</li>
<li>建立第一个 <code>block</code>，把 <code>downsample</code> 传给 <code>block</code> 作为降采样的层，并且 <code>stride</code> 也使用传入的 <code>stride</code>（stride&#x3D;2）。<strong>后面我们会分析 <code>downsample</code> 层在 <code>BasicBlock</code> 和 <code>Bottleneck</code> 中，具体是怎么用的</strong>。</li>
<li>改变通道数<code>self.inplanes = planes * block.expansion</code>。<ul>
<li>在 <code>BasicBlock</code> 里，<code>expansion=1</code>，因此这一步<strong>不会改变通道数</strong>。</li>
<li>在 <code>Bottleneck</code> 里，<code>expansion=4</code>，因此这一步<strong>会改变通道数</strong>。</li>
</ul>
</li>
<li>图片经过第一个 <code>block</code>后，就会改变通道数和图片大小。接下来 for 循环添加剩下的 <code>block</code>。从第 2 个 <code>block</code> 起，输入和输出通道数是相等的，因此就不用传入 <code>downsample</code> 和 <code>stride</code>（那么 <code>block</code> 的 <code>stride</code> 默认使用 1，下面我们会分析 <code>BasicBlock</code> 和 <code>Bottleneck</code> 的源码）。</li>
</ul>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">def _make_layer(self, <span class="hljs-keyword">block, </span>planes, <span class="hljs-keyword">blocks, </span>stride=<span class="hljs-number">1</span>, <span class="hljs-keyword">dilate=False):</span><br><span class="hljs-keyword"></span>    <span class="hljs-keyword">norm_layer </span>= self._norm_layer<br>    downsample = None<br>    previous_dilation = self.<span class="hljs-keyword">dilation</span><br><span class="hljs-keyword"></span>    if <span class="hljs-keyword">dilate:</span><br><span class="hljs-keyword"></span>        self.<span class="hljs-keyword">dilation </span>*= stride<br>        stride = <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 首先判断 stride 是否为1，输入通道和输出通道是否相等。不相等则使用 1 X 1 的卷积改变大小和通道</span><br>    <span class="hljs-comment">#作为 downsample</span><br>    <span class="hljs-comment"># 在 Resnet 中，每层 layer 传入的 stride =2</span><br>    if stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or </span>self.inplanes != planes * <span class="hljs-keyword">block.expansion:</span><br><span class="hljs-keyword"></span>        downsample = nn.Sequential(<br>            conv1x1(self.inplanes, planes * <span class="hljs-keyword">block.expansion, </span>stride),<br>            <span class="hljs-keyword">norm_layer(planes </span>* <span class="hljs-keyword">block.expansion),</span><br><span class="hljs-keyword"></span>        )<br><br>    layers = []<br>    <span class="hljs-comment"># 然后添加第一个 basic block，把 downsample 传给 BasicBlock 作为降采样的层。</span><br>    layers.append(<span class="hljs-keyword">block(self.inplanes, </span>planes, stride, downsample, self.groups,<br>                        self.<span class="hljs-keyword">base_width, </span>previous_dilation, <span class="hljs-keyword">norm_layer))</span><br><span class="hljs-keyword"></span>    <span class="hljs-comment"># 修改输出的通道数            </span><br>    self.inplanes = planes * <span class="hljs-keyword">block.expansion</span><br><span class="hljs-keyword"></span>    <span class="hljs-comment"># 继续添加这个 layer 里接下来的 BasicBlock</span><br>    for _ in range(<span class="hljs-number">1</span>, <span class="hljs-keyword">blocks):</span><br><span class="hljs-keyword"></span>        layers.append(<span class="hljs-keyword">block(self.inplanes, </span>planes, groups=self.groups,<br>                            <span class="hljs-keyword">base_width=self.base_width, </span><span class="hljs-keyword">dilation=self.dilation,</span><br><span class="hljs-keyword"></span>                            <span class="hljs-keyword">norm_layer=norm_layer))</span><br><span class="hljs-keyword"></span><br>    return nn.Sequential(*layers)<br></code></pre></td></tr></table></figure>

<p>下面来看 <code>BasicBlock</code> 和 <code>Bottleneck</code> 的源码。</p>
<h3 id="BasicBlock"><a href="#BasicBlock" class="headerlink" title="BasicBlock"></a>BasicBlock</h3><h4 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h4><p><code>BasicBlock</code> 构造函数的主要参数如下：</p>
<ul>
<li>inplanes：输入通道数。</li>
<li>planes：输出通道数。</li>
<li>stride：第一个卷积层的 <code>stride</code>。</li>
<li>downsample：从 <code>layer</code> 中传入的 <code>downsample</code> 层。</li>
<li>groups：分组卷积的分组数，使用 1</li>
<li>base_width：每组卷积的通道数，使用 64</li>
<li>dilation：空洞卷积，为1，表示不使用 空洞卷积</li>
</ul>
<p>主要流程如下：</p>
<ul>
<li>首先判断是否传入了 <code>norm_layer</code> 层，如果没有，则使用 <code>BatchNorm2d</code>。</li>
<li>校验参数：<code>groups == 1</code>，<code>base_width == 64</code>，<code>dilation == 1</code>。也就是说，在 <code>BasicBlock</code> 中，不使用空洞卷积和分组卷积。 </li>
<li>定义第 1 组 <code>conv3x3 -&gt; norm_layer -&gt; relu</code>，这里使用传入的 <code>stride</code> 和 <code>inplanes</code>。（<strong>如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>BasicBlock</code>，那么 <code>stride=2</code>，这里会降采样和改变通道数</strong>）。</li>
<li>定义第 2 组 <code>conv3x3 -&gt; norm_layer -&gt; relu</code>，这里不使用传入的 <code>stride</code> （默认为 1），输入通道数和输出通道数使用<code>planes</code>，也就是<strong>不需要降采样和改变通道数</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicBlock</span>(nn.Module):<br>    expansion = <span class="hljs-number">1</span><br>    __constants__ = [<span class="hljs-string">&#x27;downsample&#x27;</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inplanes, planes, stride=<span class="hljs-number">1</span>, downsample=<span class="hljs-literal">None</span>, groups=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 base_width=<span class="hljs-number">64</span>, dilation=<span class="hljs-number">1</span>, norm_layer=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(BasicBlock, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            norm_layer = nn.BatchNorm2d<br>        <span class="hljs-keyword">if</span> groups != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> base_width != <span class="hljs-number">64</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;BasicBlock only supports groups=1 and base_width=64&#x27;</span>)<br>        <span class="hljs-keyword">if</span> dilation &gt; <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;Dilation &gt; 1 not supported in BasicBlock&quot;</span>)<br>        <span class="hljs-comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span><br>        <span class="hljs-variable language_">self</span>.conv1 = conv3x3(inplanes, planes, stride)<br>        <span class="hljs-variable language_">self</span>.bn1 = norm_layer(planes)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = conv3x3(planes, planes)<br>        <span class="hljs-variable language_">self</span>.bn2 = norm_layer(planes)<br>        <span class="hljs-variable language_">self</span>.downsample = downsample<br>        <span class="hljs-variable language_">self</span>.stride = stride<br></code></pre></td></tr></table></figure>

<h4 id="forward-1"><a href="#forward-1" class="headerlink" title="forward()"></a>forward()</h4><p><code>forward()</code> 方法的主要流程如下：</p>
<ul>
<li><code>x</code> 赋值给 <code>identity</code>，用于后面的 <code>shortcut</code> 连接。</li>
<li><code>x</code> 经过第 1 组 <code>conv3x3 -&gt; norm_layer -&gt; relu</code>，如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>BasicBlock</code>，那么 <code>stride=2</code>，第一个卷积层会降采样。</li>
<li><code>x</code> 经过第 1 组 <code>conv3x3 -&gt; norm_layer</code>，得到 <code>out</code>。</li>
<li>如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>BasicBlock</code>，那么 <code>downsample</code> 不为空，会经过 <code>downsample</code> 层，得到 <code>identity</code>。</li>
<li>最后将 <code>identity</code> 和 <code>out</code> 相加，经过 <code>relu</code> ，得到输出。</li>
</ul>
<blockquote>
<p>注意，2 个卷积层都需要经过 <code>relu</code> 层，但它们使用的是同一个 <code>relu</code> 层。</p>
</blockquote>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span></span>(<span class="hljs-keyword">self</span>, x):<br>    identity = x<br>    <span class="hljs-comment"># 如果是 layer2，layer3，layer4 里的第一个 BasicBlock，第一个卷积层会降采样</span><br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.conv1(x)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.bn1(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.relu(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.conv2(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.bn2(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.downsample is not <span class="hljs-symbol">None:</span><br>        identity = <span class="hljs-keyword">self</span>.downsample(x)<br><br>    <span class="hljs-keyword">out</span> += identity<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.relu(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">out</span><br></code></pre></td></tr></table></figure>

<h3 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h3><h4 id="构造函数-2"><a href="#构造函数-2" class="headerlink" title="构造函数"></a>构造函数</h4><p>参数如下：</p>
<ul>
<li>inplanes：输入通道数。</li>
<li>planes：输出通道数。</li>
<li>stride：第一个卷积层的 <code>stride</code>。</li>
<li>downsample：从 <code>layer</code> 中传入的 <code>downsample</code> 层。</li>
<li>groups：分组卷积的分组数，使用 1</li>
<li>base_width：每组卷积的通道数，使用 64</li>
<li>dilation：空洞卷积，为1，表示不使用 空洞卷积</li>
</ul>
<p>主要流程如下：</p>
<ul>
<li>首先判断是否传入了 <code>norm_layer</code> 层，如果没有，则使用 <code>BatchNorm2d</code>。</li>
<li>计算 <code>width</code>，等于传入的 <code>planes</code>，用于中间的 $ 3 \times 3 $ 卷积。 </li>
<li>定义第 1 组 <code>conv1x1 -&gt; norm_layer</code>，这里不使用传入的 <code>stride</code>，使用 <code>width</code>，作用是进行降维，减少通道数。</li>
<li>定义第 2 组 <code>conv3x3 -&gt; norm_layer</code>，这里使用传入的 <code>stride</code>，输入通道数和输出通道数使用<code>width</code>。（<strong>如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>Bottleneck</code>，那么 <code>stride=2</code>，这里会降采样</strong>）。</li>
<li>定义第 3 组 <code>conv1x1 -&gt; norm_layer</code>，这里不使用传入的 <code>stride</code>，使用 <code>planes * self.expansion</code>，作用是进行升维，增加通道数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bottleneck</span>(nn.Module):<br>    expansion = <span class="hljs-number">4</span><br>    __constants__ = [<span class="hljs-string">&#x27;downsample&#x27;</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inplanes, planes, stride=<span class="hljs-number">1</span>, downsample=<span class="hljs-literal">None</span>, groups=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 base_width=<span class="hljs-number">64</span>, dilation=<span class="hljs-number">1</span>, norm_layer=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(Bottleneck, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            norm_layer = nn.BatchNorm2d<br><br>        <span class="hljs-comment"># base_width = 64</span><br>        <span class="hljs-comment"># groups =1</span><br>        <span class="hljs-comment"># width = planes</span><br>        width = <span class="hljs-built_in">int</span>(planes * (base_width / <span class="hljs-number">64.</span>)) * groups<br>        <span class="hljs-comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span><br>        <span class="hljs-comment"># 1x1 的卷积是为了降维，减少通道数</span><br>        <span class="hljs-variable language_">self</span>.conv1 = conv1x1(inplanes, width)<br>        <span class="hljs-variable language_">self</span>.bn1 = norm_layer(width)<br>        <span class="hljs-comment"># 3x3 的卷积是为了改变图片大小，不改变通道数</span><br>        <span class="hljs-variable language_">self</span>.conv2 = conv3x3(width, width, stride, groups, dilation)<br>        <span class="hljs-variable language_">self</span>.bn2 = norm_layer(width)<br>        <span class="hljs-comment"># 1x1 的卷积是为了升维，增加通道数，增加到 planes * 4</span><br>        <span class="hljs-variable language_">self</span>.conv3 = conv1x1(width, planes * <span class="hljs-variable language_">self</span>.expansion)<br>        <span class="hljs-variable language_">self</span>.bn3 = norm_layer(planes * <span class="hljs-variable language_">self</span>.expansion)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.downsample = downsample<br>        <span class="hljs-variable language_">self</span>.stride = stride<br></code></pre></td></tr></table></figure>

<h4 id="forward-2"><a href="#forward-2" class="headerlink" title="forward()"></a>forward()</h4><p><code>forward()</code> 方法的主要流程如下：</p>
<ul>
<li><code>x</code> 赋值给 <code>identity</code>，用于后面的 <code>shortcut</code> 连接。</li>
<li><code>x</code> 经过第 1 组 <code>conv1x1 -&gt; norm_layer -&gt; relu</code>，作用是进行降维，减少通道数。</li>
<li><code>x</code> 经过第 2 组 <code>conv3x3 -&gt; norm_layer -&gt; relu</code>。如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>Bottleneck</code>，那么 <code>stride=2</code>，第一个卷积层会降采样。</li>
<li><code>x</code> 经过第 1 组 <code>conv1x1 -&gt; norm_layer -&gt; relu</code>，作用是进行降维，减少通道数。</li>
<li>如果是 <code>layer2</code> ，<code>layer3</code> ，<code>layer4</code> 里的第一个 <code>Bottleneck</code>，那么 <code>downsample</code> 不为空，会经过 <code>downsample</code> 层，得到 <code>identity</code>。</li>
<li>最后将 <code>identity</code> 和 <code>out</code> 相加，经过 <code>relu</code> ，得到输出。</li>
</ul>
<blockquote>
<p>注意，3 个卷积层都需要经过 <code>relu</code> 层，但它们使用的是同一个 <code>relu</code> 层。</p>
</blockquote>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span></span>(<span class="hljs-keyword">self</span>, x):<br>    identity = x<br><br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.conv1(x)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.bn1(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.relu(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.conv2(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.bn2(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.relu(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.conv3(<span class="hljs-keyword">out</span>)<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.bn3(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.downsample is not <span class="hljs-symbol">None:</span><br>        identity = <span class="hljs-keyword">self</span>.downsample(x)<br><br>    <span class="hljs-keyword">out</span> += identity<br>    <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.relu(<span class="hljs-keyword">out</span>)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">out</span><br></code></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后，总结一下。</p>
<ul>
<li><code>BasicBlock</code>  中有 1 个 $3 \times 3 $卷积层，如果是 <code>layer</code> 的第一个 <code>BasicBlock</code>，那么第一个卷积层的 <code>stride=2</code>，作用是进行降采样。</li>
<li><code>Bottleneck</code>  中有 2 个 $1 \times 1 $卷积层， 1 个 $3 \times 3 $ 卷积层。先经过第 1 个 $1 \times 1 $卷积层，进行降维，然后经过 $3 \times 3 $卷积层（如果是 <code>layer</code> 的第一个 <code>Bottleneck</code>，那么 $3 \times 3 $ 卷积层的 <code>stride=2</code>，作用是进行降采样），最后经过 $1 \times 1 $卷积层，进行升维 。</li>
</ul>
<h3 id="ResNet-18-图解"><a href="#ResNet-18-图解" class="headerlink" title="ResNet 18 图解"></a>ResNet 18 图解</h3><h4 id="layer1"><a href="#layer1" class="headerlink" title="layer1"></a>layer1</h4><p>下面是 <code>ResNet 18</code> ，使用的是 <code>BasicBlock</code> 的 <code>layer1</code>，特点是没有进行降采样，卷积层的 <code>stride = 1</code>，不会降采样。在进行 <code>shortcut</code> 连接时，也没有经过 <code>downsample</code> 层。</p>
<p><img src="/img/pytorchtrain8/5.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="layer2，layer3，layer4"><a href="#layer2，layer3，layer4" class="headerlink" title="layer2，layer3，layer4"></a>layer2，layer3，layer4</h4><p>而 <code>layer2</code>，<code>layer3</code>，<code>layer4</code> 的结构图如下，每个 <code>layer</code> 包含 2 个 <code>BasicBlock</code>，但是第 1 个 <code>BasicBlock</code> 的第 1 个卷积层的 <code>stride = 2</code>，会进行降采样。<strong>在进行 <code>shortcut</code> 连接时，会经过 <code>downsample</code> 层，进行降采样和降维</strong>。</p>
<p><img src="/img/pytorchtrain8/6.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="ResNet-50-图解"><a href="#ResNet-50-图解" class="headerlink" title="ResNet 50 图解"></a>ResNet 50 图解</h3><h4 id="layer1-1"><a href="#layer1-1" class="headerlink" title="layer1"></a>layer1</h4><p>在 <code>layer1</code> 中，首先第一个 <code>Bottleneck</code> 只会进行升维，不会降采样。<code>shortcut</code> 连接前，会经过 <code>downsample</code> 层升维处理。第二个 <code>Bottleneck</code> 的 <code>shortcut</code> 连接不会经过 <code>downsample</code> 层。</p>
<p><img src="/img/pytorchtrain8/7.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="layer2，layer3，layer4-1"><a href="#layer2，layer3，layer4-1" class="headerlink" title="layer2，layer3，layer4"></a>layer2，layer3，layer4</h4><p>而 <code>layer2</code>，<code>layer3</code>，<code>layer4</code> 的结构图如下，每个 <code>layer</code> 包含多个 <code>Bottleneck</code>，但是第 1 个 <code>Bottleneck</code> 的 $ 3 \times 3 $ 卷积层的 <code>stride = 2</code>，会进行降采样。<strong>在进行 <code>shortcut</code> 连接时，会经过 <code>downsample</code> 层，进行降采样和降维</strong>。</p>
<p><img src="/img/pytorchtrain8/8.png" srcset="/img/loading.gif" lazyload></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#深度学习</a>
      
        <a href="/tags/pytorch/" class="print-no-link">#pytorch</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深度学习-15-pytorch-8-具体网络分析</div>
      <div>https://truth-zheng.github.io/2021/08/15/pytorchtrain8/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>zheng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年8月15日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/14/pytorchtrain7/" title="深度学习-14-pytorch-7-模型补充操作">
                        <span class="hidden-mobile">深度学习-14-pytorch-7-模型补充操作</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://github.com" target="_blank" rel="nofollow noopener"><span>Github</span></a> <i class="iconfont icon-love"></i> <a href="https://scholar.google.com/" target="_blank" rel="nofollow noopener"><span>GoogleScholar</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
